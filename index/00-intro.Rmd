<!-- The {.unnumbered} option here means that the introduction will be "Chapter 0." You can also use {-} for no numbers on chapters. -->

```{r load_pkgs, message=FALSE, echo=FALSE}
# List of packages required for this analysis
pkg <- c("dplyr", "ggplot2", "knitr", "bookdown", "devtools")
# Check if packages are not installed and assign the
# names of the packages not installed to the variable new.pkg
new.pkg <- pkg[!(pkg %in% installed.packages())]
# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg))
  install.packages(new.pkg, repos = "http://cran.rstudio.com")
# Load packages
library(aggiedown)
library(knitr)
```

# Introduction {-}

## Motivation

* Scaling sequence analysis
* Improving accessibility
* Overly-deep pipelines / intermediate data
* Sea-change toward streaming methods due to nanopore

## Background

* Sequencing technology
    * Second-gen HTS: illumina
    * Long read tech: pacbio
    * Real-time sequencing: nanopore
* Streaming Algorithms
    * Definitions
        * Offline algs
        * semi-streaming algs
    * Advantages
        * Implied dynamic data structures
        * Disk space efficiency
        * Removal of intermediate output
        * Infinite-size data
        * Real-time analysis
    * In \*omics
        * Hardware level: ONT
        * Abundance estimation
        * Classification (signatures)
        * k-mer cardinality
        * k-mer statistics (kmerstream)
        * assembly (semi-streaming)
        * scaffolding
* de Bruijn Graphs
    * Motivation / Uses
        * exact overlap detection
        * assembly
        * classification
        * sequence comparison
        * graph alignment
    * Definitions
        * k-mers
        * node vs edge centric
        * neighbor-finding
        * bidirectional dBG
        * traversal
    * Representations
        * Offline
            * Suffix trees
            * FM-index
            * bitmaps
            * BF + crit false positives
            * cascading BF
        * Streaming
            * (exact) hash tables
            * bloom filters
            * count-min sketch
            * quotient filter
    * Tagging / partitioning
        * Why
            * seeding for traversal
            * alignment-free comparison
            * locking / parallel construction
            * sparse-graph construction
        * Greedy k-mer subset (khmer, SparseAssembler)
        * (W,K) Minimizers
        * r-dom sets
        * Universal k-mer hitting sets
    * Implementations: offline
        * So many k-mer counters
        * GATB
        * So many assemblers: AbySS, velvet, IDBA, megahit, ALLPATHS
    * Implementations: streaming
        * khmer/oxli
* compact de Bruijn graphs
    * Motivation
        * Compressed dBG representation
        * Preserve dBG properties: implicit edges
    * Definitions:
        * From "chunks" (OLC) to dBG models
        * decision k-mers
        * Unitigs
        * Maximal unitigs
        * Simpletigs
    * Implementations: offline
        * BCALM
        * TwoPaCo
        * As components of assemblers: Abyss, etc
    * Implementations: semi-streaming
        * Faucet
        * LightAssembler
* saturation
    * Definitions of saturation
        * Accumulation of information vs error
        * by minimizing fragmentation
        * by coverage profile
        * by completeness: gene content, etc (BUSCO)
    * By context
        * Genomic vs txomic vs mtomic
        * downstream goals: assembly, classifcation, abundance
* Sketching


### Streaming Algorithms

Streaming, or online, algorithms are those that process data in the *stream model*: a stream of data is fed to the algorithm, one observation at a time in the order of arrival, and each item is processed at most once.
Alternatively, we can say that a streaming algorithm makes at most one pass over the input data.
The stream may either be finite or infinite; when we conceptualize by number of passes, we generally are considering finite streams.
A closely related group is the semi-streaming algorithm, which are those that make *few* passes over the data, typically two or less.
These algorithms are of course concerned with finite streams of data.

Streaming approaches find the most use when data is too large to fit in main memory; for example, massive network traffic data may only be concerned with some properties of the underlying graph and be much too large for main memory, necessitating streaming approaches that drill down specifically to those properties.



### de Bruijn Graphs and Their Uses in Omics

A de Bruijn graph (dBG) $G(k, \Sigma)$ is a directed graph defined by its nodes, which are a set of fixed-length sequences of length $k$ over an alphabet $\Sigma$, and its edges, which exist when the sequences of a pair of nodes share a length $k-1$ suffix and prefix.
These length-$k$ sequences are referred to as $k$-mers, and the terms nodes and $k$-mers may be used interchangeably.
This means that $G(k, \Sigma)$ has a maximum number of nodes $\| \Sigma \|^k$ and each node has a maximum in and out degree of $\| \Sigma \|$.
If we define $pre(n_i)$ to be the length $k-1$ prefix of some node $n_i \in G$ and $suf(n_i)$ to be the length $k-1$ suffix, the out-neighbors of $n_i$ can be discovered by querying $\{ suf(n_i) + s,  \forall s \in \Sigma \}$ and the in-neighbors accordingly: that is to say, in this construction, known as the *node-centric* de Bruijn graph, the edges are implied by the set of nodes, and it is only necessary to use an efficient set data structure to implement a basic dBG.

Let $\delta_in(v)$ be the in-degree of a node $v$, and $delta_out(v)$ be the out-degree of a node $v$.
The nodes in a dBG with in on out-degree greater than $1$ are *decision nodes*, their associated $k$-mers *decision $k$-mers*.

de Bruijn graphs have been used to great effect in genomics applications since they were first applied to them [@myers_toward_1995].
The principle advantage of the dBG is its simplification of the process of overlap detection between sequences: $k$-mers can stored as hashed integers for faster querying, and length $k-1$ overlaps can be discovered by using the same method as edge detection.
Hence, when a collection of sequences sampled from an underlying larger set of sequences is broken down into its constituent $k$-mers as a dBG, all $k$-mer overlaps are known implicitly. This property, and the methods extending it, can be used for genome assembly, sequence classification and comparison, genomic variant discovery, and full graph-based alignment.

### Compact de Bruijn Graphs

While the standard de Bruijn graph is a useful abstraction, in practice, most implementations only use it as an intermediate representation.
The reasons are twofold: firstly, because genomic dBGs tend to consist of many linear paths of $k$-mers with in- and out-degree of $1$, such graphs contain large quantities of redundant $k$-mers; secondly, because $k$-mers are exact substrings over a sliding window on the input sequences, each error or point mutation in introduces $k$ new nodes in the graph.
As a result, even small error and polymorphism rates in moderate sized data produce graphs with hundreds of millions or billions of nodes.

These problems are addresses by the Compact de Bruijn Graph (cDBG).
In the cDBG, paths of the form $v_0 \rightarrow ... v_n$ where $delta_out(v_0) = 1$, $delta_in(v_{1..n-1})$ and $delta_out(v_{1...n-1})$ are $1$, and $delta_in(v_n) = 1$ are compacted into single nodes; that is, linear paths are reduced to single nodes defined by their sequence, and the ends of these sequences may be either tips (that is, they have degree zero) or decision $k$-mers.
This representation preserves the implicit edge definition, while avoiding the high overhead of storing redundant $k$-mers.

The compacted nodes, and their associated sequences, are referred to as *unitigs*.
A unitig that can not be extended in either direction is a *maximal unitig*.

#### cDBG Representations

There are a variety of data models for representing the cDBG.
The simplest is a flat collection of unitigs; edges can be inferred by storing only the unitig ends, which correspond to the decision $k$-mers and tips, and querying these ends for neighbors.


#### de Bruijn Graph Tagging and Partitioning

