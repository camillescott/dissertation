<!-- The {.unnumbered} option here means that the introduction will be "Chapter 0." You can also use {-} for no numbers on chapters. -->

```{r load_pkgs, message=FALSE, echo=FALSE}
# List of packages required for this analysis
pkg <- c("dplyr", "ggplot2", "knitr", "bookdown", "devtools")
# Check if packages are not installed and assign the
# names of the packages not installed to the variable new.pkg
new.pkg <- pkg[!(pkg %in% installed.packages())]
# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg))
  install.packages(new.pkg, repos = "http://cran.rstudio.com")
# Load packages
library(aggiedown)
library(knitr)
```

# Introduction {-}

## Motivation

* Scaling sequence analysis
* Improving accessibility
* Overly-deep pipelines / intermediate data
* Sea-change toward streaming methods due to nanopore

## Background

* Sequencing technology
    * Second-gen HTS: illumina
    * Long read tech: pacbio
    * Real-time sequencing: nanopore
* Streaming Algorithms
    * Definitions
        * Offline algs
        * semi-streaming algs
    * Advantages
        * Implied dynamic data structures
        * Disk space efficiency
        * Removal of intermediate output
        * Infinite-size data
        * Real-time analysis
    * In \*omics
        * Hardware level: ONT
        * Abundance estimation
        * Classification (signatures)
        * k-mer cardinality
        * k-mer statistics (kmerstream)
        * assembly (semi-streaming)
        * scaffolding
* de Bruijn Graphs
    * Motivation / Uses
        * exact overlap detection
        * assembly
        * classification
        * sequence comparison
        * graph alignment
    * Definitions
        * k-mers
        * node vs edge centric
        * neighbor-finding
        * bidirectional dBG
        * traversal
    * Representations
        * Offline
            * Suffix trees
            * FM-index
            * bitmaps
            * BF + crit false positives
            * cascading BF
        * Streaming
            * (exact) hash tables
            * bloom filters
            * count-min sketch
            * quotient filter
    * Tagging / partitioning
        * Why
            * seeding for traversal
            * alignment-free comparison
            * locking / parallel construction
            * sparse-graph construction
        * Greedy k-mer subset (khmer, SparseAssembler)
        * (W,K) Minimizers
        * r-dom sets
        * Universal k-mer hitting sets
    * Implementations: offline
        * So many k-mer counters
        * GATB
        * So many assemblers: AbySS, velvet, IDBA, megahit, ALLPATHS
    * Implementations: streaming
        * khmer/oxli
* compact de Bruijn graphs
    * Motivation
        * Compressed dBG representation
        * Preserve dBG properties: implicit edges
    * Definitions:
        * From "chunks" (OLC) to dBG models
        * decision k-mers
        * Unitigs
        * Maximal unitigs
        * Simpletigs
    * Implementations: offline
        * BCALM
        * TwoPaCo
        * As components of assemblers: Abyss, etc
    * Implementations: semi-streaming
        * Faucet
        * LightAssembler
* saturation
    * Definitions of saturation
        * Accumulation of information vs error
        * by minimizing fragmentation
        * by coverage profile
        * by completeness: gene content, etc (BUSCO)
    * By context
        * Genomic vs txomic vs mtomic
        * downstream goals: assembly, classifcation, abundance
* Sketching





### de Bruijn Graphs and Their Uses in Omics

A de Bruijn graph (dBG) $G(k, \Sigma)$ is a directed graph defined by its nodes, which are a set of fixed-length sequences of length $k$ over an alphabet $\Sigma$, and its edges, which exist when the sequences of a pair of nodes share a length $k-1$ suffix and prefix.
This means that $G(k, \Sigma)$ has a maximum number of nodes $\| \Sigma \|^k$ and each node has a maximum in and out degree of $\| \Sigma \|$.
If we define $pre(n_i)$ to be the length $k-1$ prefix of some node $n_i \in G$ and $suf(n_i)$ to be the length $k-1$ suffix, the out-neighbors of $n_i$ can be discovered by querying $\{ suf(n_i) + s,  \forall s \in \Sigma \}$ and the in-neighbors accordingly: that is to say, in this construction, known as the *node-centric* de Bruijn graph, the edges are implied by the set of nodes, and it is only necessary to use an efficient set data structure to implement a basic dBG.

The length-$K$ sequences making up a dBG are referred to as $k$-mers.
The nodes in a dBG with in on out-degree greater than $1$ are *decision nodes*, their associated $k$-mers *decision $k$-mers*.

de Bruijn graphs have been used to great effect in genomics applications since they were first applied to them [@myers_toward_1995].
The principle advantage of the dBG is its simplification of the process of overlap detection between sequences: $k$-mers can stored as hashed integers for faster querying, and length $k-1$ overlaps can be discovered by using the same method as edge detection.
Hence, when a collection of sequences sampled from an underlying larger set of sequences is broken down into its constituent $k$-mers as a dBG, all $k$-mer overlaps are known implicitly. This property, and the methods extending it, can be used for genome assembly, sequence classification and comparison, genomic variant discovery, and full graph-based alignment.

#### Compact de Bruijn Graphs

While the standard de Bruijn graph is a useful abstraction, in practice, most implementations only use it as an intermediate representation.
The reasons are twofold: firstly, because genomic dBGs tend to consist of many linear paths of $k$-mers with in and out-degree of $1$, such graphs contain large quantities of redundant $k$-mers; secondly, because $k$-mers are exact substrings over a sliding window on the input sequences, each error or point mutation in introduces $k$ new nodes in the graph.
As a result, even small error and polymorphism rates in moderate sized data produce graphs with hundreds of millions or billions of nodes.

