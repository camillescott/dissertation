```{r include_packages_2, include = FALSE}
# This chunk ensures that the huskydown package is
# installed and loaded. This huskydown package includes
# the template files for the thesis and also two functions
# used for labeling and referencing
if (!require(devtools))
  install.packages("devtools", repos = "http://cran.rstudio.com")
if (!require(dplyr))
    install.packages("dplyr", repos = "http://cran.rstudio.com")
if (!require(ggplot2))
    install.packages("ggplot2", repos = "http://cran.rstudio.com")
if (!require(ggplot2))
    install.packages("bookdown", repos = "http://cran.rstudio.com")
if (!require(aggiedown)) {
  library(devtools)
  devtools::install_github("rapeek/aggiedown")
  }
library(aggiedown)
```


# dammit 2.0: an open, accessible transcriptome annotator
\chaptermark {dammit annotator}

\begin{sizepar}{16}{24}
\begin{description}

\item[Chapter Authors]
Camille Scott and N. Tessa Pierce

\item[DOI]
\url{https://doi.org}

\end{description}
\end{sizepar}

## Abstract

dammit is a automated de novo transcriptome annotation pipeline designed with the express purpose of being easy to install and configure.
While a number of annotation protocols and software pipelines already existed when dammit was first conceived, they tended to be unapproachable to beginners.
dammit automates database download and preparation, as well as dependency installation; it need only be installed as a Python package via PyPI or conda, after Snakemake is used internally to manage environments for each annotation step.
Annotation is achieved through homology searches against protein databases, hidden Markov model and covariance model profile searching for protein domains and non-coding RNAs, gene model prediction, completeness
assessment, and orthology searches against user databases.
dammit uses mostly easily available software such as hmmer and Infernal, occasionally making use of less well-known software in the pursuit of performance.
The resulting annotations are collected and merged into a Generic Feature Format Version 3 (GFF3) file, with annotation summaries added to FASTA headers.
dammit also exposes a suite of simple command line tools for file formation conversion, homology filtering, metrics, and FASTA munging.

## Introduction

RNA-seq is now a foundational tool for genomics.
Reference-based RNA-seq enables researchers to characterize gene expression levels under differing conditions, while de novo assemblies of RNA-seq data provide a useful resource for researchers attempting to characterize the gene content of an organism, especially in non-model systems [@garber_computational_2011].
Importantly, due to its cost-effectiveness, transcriptome assembly is an accessible option for labs with limited resources; whereas a complete de novo genome assembly requires high coverage and often long reads to properly characterize genic content, a transcriptome assembly is often sufficient to discover expressed transcripts of interest.
Annotation is generally the first step downstream of assembly, and annotators often make for complex and unwieldy software.
Due to their tendency to rely on a variety of third-party software and databases, they can be difficult to install and configure, especially for those with limited bioinformatics expertise.
To make matters worse, many annotators trade performance for familiarity in their supporting software; for example, while many aspiring bioinformaticians may be familiar with BLAST [@altschul_basic_1990], its relatively lackluster performance when comparing many transcripts to a large reference database can be a burden to labs with limited computational resources. 

dammit addresses these issues by fully embracing a philosophy of openness and accessibility.
The authors contend that truly open scientific software must also maximize *accessibility* and *availability*: tools with cumbersome installation processes, cloud-based solutions that rely on stable centralized hosting, and tools that only run on a limited selection of operating systems and hardware are compromised in their support of open science.
Hence, we rely on performant, well-tested open source third-party tools; implement our core software in a well supported language environment; and use the stable, easily accessible `conda` ecosystem for distribution. 
dammit provides a solution for users wanting automated local installation, good performance, and ease-of-use.

## Methods

### Implementation

dammit is written in Python and uses tools within the ecosystem.
The first version was written using `pydoit` [@url:http://pydoit.org], with each step in the database preparation and annotation process decomposed into a `pydoit` task, allowing for easy dependency tracking and resume capability.
Version 2 is a complete rewrite using Snakemake [@doi:10.12688/f1000research.29032.1]; while the underlying pipeline remains mostly the same, the `pydoit` tasks have been converted into reusable Snakemake wrappers and the command line interface (CLI) wraps the Snakemake CLI.
Snakemake is widely used within the field and has a rapidly growing community.
Furthermore, it enables first-class support of High Performance Compute (HPC) system schedulers, a collection of reusable wrappers to make tasks portable, and automated per-task environment management.

The dammit CLI exposes a number of subcommands.
The core `run` subcommand wraps Snakemake and executes the pipeline which is defined in the associated snakefiles.
A `config` subcommand allows reporting and editing configuration options globally and per-project; all configuration is done through standard YAML files, with global configuration and temporary storage adhering to the XDG Base Directory Specification [@url:https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html].
The remaining subcommands implement various format parsing and transformation, filtering, and statistical functions, which are then leveraged in the Snakemake pipeline.
For example, `dammit rename-fasta` parses an input FASTA file and renames the headers in a standardized format, optionally with a user-supplied regular expression; this subcommand is also the first task run by the annotation pipeline.
This allows users to make use of the internal `dammit` tooling independently of annotation.

File parsing is implemented in the companion library `ope` [@url:https://github.com/camillescott/ope].
This library provides parsing support for GFF3, HMMER and Infernal tabular output, MAF, and TransDecoder FASTA, returning the parsed data in `pandas` DataFrames [@doi:10.5281/zenodo.3715232; @doi:10.25080/Majora-92bf1922-00a] for use within the Python data science ecosystem.
`dammit` provides converters to output the corresponding DataFrames as GFF3.

dammit is primarily developed and tested on 64-bit Linux and distributed via conda.
We currently require a minimum of Python 3.7.

All documentation is written in Markdown and managed with MkDocs. Documentation can be accessed at the dammit Github Pages site [@url:http://dib-lab.github.io/dammit/].

### Operation

The program is divided into three main modules: \texttt{dammit dependencies}, which checks
that all third-party dependencies are satisfied; \texttt{dammit databases}, which checks whether
databases are installed and retrieves and prepares them if necessary; and \texttt{dammit annotate},
which contains the actual annotation pipeline. These submodules are explained in further detail in the
use cases section.

Hardware requirements vary mostly with the databases used for annotation and their preparation.
Database preparation for a default run can be completed in under 16 GB of RAM, with the most
intensive step being LAST's \texttt{lastdb}; preparation including uniref90 with the \texttt{--full} 
option uses considerably more RAM. Advanced users can make detailed adjustments to LAST's 
parameters with the config file to reduce RAM and run-time.

Annotation is less RAM intensive than the database preparation step, instead requiring more CPU time. 
gnu-parallel \cite{tange_gnu_2011} is used to help scale the more intensive tasks. A default run splits the input file across multiple cores on a single
machine. An experimental \texttt{--n-nodes} flag will attempt to scale across multiple nodes on a cluster; detailed instructions for environment
configuration with Portable Batch System are included in the documentation. A typical
run can be completed in less than 12 hours on a machine with 8 cores; once again, adding uniref90 with 
\texttt{--full} greatly increases the required time.

## Use Cases

### Database Preparation

Annotation necessarily requires a number of databases. dammit automates the retrieval and 
preparation of its databases with the \texttt{dammit databases} submodule. Running this
submodule checks for their presence by default; with the \texttt{--install} flag, they will be
downloaded and prepared. dammit uses the following databases: 

\begin{itemize}
\item \textbf{Pfam-A}: Profile hidden markov models for searching protein domains with hmmer \cite{finn_pfam_2016}.
\item \textbf{Rfam}: Covariance models for searching RNA secondary structure with Infernal \cite{griffiths-jones_rfam:_2003}.
\item \textbf{OrthoDB}: Hierarchical collection of protein ortholog groups \cite{kriventseva_orthodb_2015}.
\item \textbf{BUSCO}: Collections of core genes for major domains of life. dammit can use metazoa, vertebrata, arthropoda, and eukaryota \cite{simao_busco:_2015}.
\item \textbf{uniref90}: A comprehensive collection of most known proteins clustered at 90\% sequence similarity \cite{suzek_uniref:_2007} Only downloaded when the
\texttt{--full} option is used.
\end{itemize}

Databases are stored in the users home directory by default,
and the location can be changed either with the \texttt{--database-dir} flag or by setting a 
\texttt{DAMMIT\textunderscore DB\textunderscore DIR} environment variable. 

### Annotation Pipeline

\texttt{dammit annotate} takes a "standard" FASTA file as input. First, the FASTA headers are renamed and a mapping between the original
and new names is output; this avoids the issues that some programs have with certain characters in the header lines. Then, a basic
set of sequence statistics are gathered, such as the number of transcripts, the $k$-mer redundancy, and the GC percent. BUSCO 
\cite{simao_busco:_2015} is run 
in transcriptome mode to assess completeness using whichever BUSCO database is specified by the user. 
TransDecoder.LongOrfs \cite{haas_novo_2013} then finds
open reading frames and produces a set of basic protein translations; these translations are used to search against Pfam-A with
hmmer \cite{durbin_biological_1998},
which are then fed into TransDecoder.Predict to get a final set of gene model predictions. Infernal \cite{nawrocki_infernal_2013} 
is used to search Rfam for ncRNAs.
OrthoDB v8 and optionally uniref90 are searched using LAST \cite{sheetlin_frameshift_2014,kielbasa_adaptive_2011}
If the user supplies any custom protein databases, they are searched for orthologs using Conditional Reciprocal Best Hits \cite{aubry_deep_2014}.

An example annotation run on the file \texttt{cdna.fa} with the user-supplied protein database \texttt{pep.fa} might look like so:

\texttt{dammit annotate cdna.fa --user-databases pep.fa --busco-group eukaryota --n\textunderscore threads 2}

This will create a new folder called \texttt{cdna.fa.dammit}, which can be changed with the \texttt{--output} flag.
This folder contains the files \texttt{cdna.fa.dammit.gff3} and \texttt{cdna.fa.dammit.fa}
with the main results, along with
many intermediate files. The GFF3 file contains the aggregated results, with coordinates in transcript space; this file
can be furthered interrogated downstream with other analysis packages or viewed with an explorer such as IGV \cite{robinson_integrative_2011}.
The GFF3 uses terms compliant with the Sequence Ontology Project \cite{eilbeck_sequence_2005}. dammit also outputs a new
FASTA file with summary annotation information in each header line. 

